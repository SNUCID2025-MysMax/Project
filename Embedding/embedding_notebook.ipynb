{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50917aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install FlagEmbedding pymilvus \"pymilvus[model]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b06c8",
   "metadata": {},
   "source": [
    "# V1 - 사전 임베딩(한글)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a75f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 144134.16it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import json, pickle\n",
    "\n",
    "# 모델 초기화 (CPU/GPU 설정)\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "# with open(\"../ServiceExtraction/integration/0.1.5_embedding_all.json\", \"r\") as f:\n",
    "#     services = json.load(f)\n",
    "\n",
    "with open(\"../ServiceExtraction/integration/service_list_ver1.1.6.json\", \"r\") as f:\n",
    "    services = {}\n",
    "    data = json.load(f)\n",
    "    for device_id, device_info in data.items():\n",
    "        services[device_id] = f\"{device_info[\"info\"]}; {\";\".join(device_info[\"examples\"])}\"\n",
    "    # print(services)\n",
    "\n",
    "keys = list(services.keys())\n",
    "texts = list(services.values())\n",
    "\n",
    "# 임베딩 생성 (배치 처리)\n",
    "batch_size = 32\n",
    "dense_embeddings = []\n",
    "sparse_embeddings = []\n",
    "colbert_embeddings = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    outputs = model.encode(\n",
    "        batch, \n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=True  # ColBERT 활성화\n",
    "    )\n",
    "    dense_embeddings.extend(outputs['dense_vecs'])\n",
    "    sparse_embeddings.extend(outputs['lexical_weights'])\n",
    "    colbert_embeddings.extend(outputs['colbert_vecs'])\n",
    "\n",
    "# ColBERT 벡터 저장 전처리\n",
    "def process_colbert(embeddings):\n",
    "    \"\"\"3D 배열을 저장 가능한 형태로 변환\"\"\"\n",
    "    return [emb.astype(np.float16) for emb in embeddings]  # 절반의 저장 공간 절약\n",
    "\n",
    "processed_colbert = process_colbert(colbert_embeddings)\n",
    "\n",
    "# 변환 함수 확장\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.float16):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# 저장\n",
    "np.save('./embedding_result_v1/dense_embeddings.npy', np.array(dense_embeddings))\n",
    "# ColBERT 벡터 압축 저장\n",
    "with open('./embedding_result_v1/colbert_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_colbert, f)\n",
    "\n",
    "# float32 → float 로 강제 변환\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "serializable_sparse = convert_to_serializable(sparse_embeddings)\n",
    "\n",
    "with open('./embedding_result_v1/sparse_embeddings.json', 'w') as f:\n",
    "    json.dump(serializable_sparse, f, indent=2)\n",
    "    \n",
    "# 메타데이터 저장 (ColBERT 정보 추가)\n",
    "metadata = {\n",
    "    'keys': keys,\n",
    "    'texts': texts,\n",
    "    'colbert_shapes': [emb.shape for emb in processed_colbert]  # 원본 형태 정보\n",
    "}\n",
    "with open('./embedding_result_v1/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fe8fe",
   "metadata": {},
   "source": [
    "# V4 - 사전 임베딩(영어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0026d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 144465.12it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import json, pickle\n",
    "\n",
    "# 모델 초기화 (CPU/GPU 설정)\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "# with open(\"../ServiceExtraction/integration/0.1.5_embedding_all.json\", \"r\") as f:\n",
    "#     services = json.load(f)\n",
    "\n",
    "def optimized_weighted_string(device_info, name_weight=3):\n",
    "    # 시작: names 강화\n",
    "    start_names = [name for name in device_info[\"names\"] for _ in range(name_weight)]\n",
    "    \n",
    "    # 중간: expressions\n",
    "    middle_exprs = list(set(device_info[\"expressions\"]))\n",
    "    \n",
    "    # 끝: names 재강화  \n",
    "    end_names = [name for name in device_info[\"names\"] for _ in range(2)]\n",
    "    \n",
    "    return \". \".join(start_names + middle_exprs + end_names)\n",
    "\n",
    "# def optimized_weighted_string(device_info, name_weight=3, explanation_weight=2):\n",
    "#     # 1. 이름 강조 (앞, 중간, 끝)\n",
    "#     names = list(set(device_info.get(\"names\", [])))\n",
    "#     name_tokens = [name for name in names for _ in range(name_weight)]\n",
    "\n",
    "#     # 2. 설명 추가 (weight 적용)\n",
    "#     explanation = device_info.get(\"explanation\", \"\")\n",
    "#     explanation_tokens = [explanation] * explanation_weight if explanation else []\n",
    "\n",
    "#     # 3. 표현 다양화\n",
    "#     exprs = list(set(device_info.get(\"expressions\", [])))\n",
    "\n",
    "#     # 4. 혼합\n",
    "#     parts = name_tokens + explanation_tokens + exprs + names\n",
    "#     return \". \".join(parts)\n",
    "\n",
    "\n",
    "with open(\"../ServiceExtraction/integration/service_list_ver1.1.6.5.json\", \"r\") as f:\n",
    "    services = {}\n",
    "    data = json.load(f)\n",
    "    for device_id, device_info in data.items():\n",
    "        services[device_id] = optimized_weighted_string(device_info)\n",
    "    # print(services)\n",
    "\n",
    "keys = list(services.keys())\n",
    "texts = list(services.values())\n",
    "\n",
    "# 임베딩 생성 (배치 처리)\n",
    "batch_size = 32\n",
    "dense_embeddings = []\n",
    "sparse_embeddings = []\n",
    "colbert_embeddings = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    outputs = model.encode(\n",
    "        batch, \n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=True  # ColBERT 활성화\n",
    "    )\n",
    "    dense_embeddings.extend(outputs['dense_vecs'])\n",
    "    sparse_embeddings.extend(outputs['lexical_weights'])\n",
    "    colbert_embeddings.extend(outputs['colbert_vecs'])\n",
    "\n",
    "# ColBERT 벡터 저장 전처리\n",
    "def process_colbert(embeddings):\n",
    "    \"\"\"3D 배열을 저장 가능한 형태로 변환\"\"\"\n",
    "    return [emb.astype(np.float16) for emb in embeddings]  # 절반의 저장 공간 절약\n",
    "\n",
    "processed_colbert = process_colbert(colbert_embeddings)\n",
    "\n",
    "# 변환 함수 확장\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.float16):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# 저장\n",
    "np.save('./embedding_result_v4/dense_embeddings.npy', np.array(dense_embeddings))\n",
    "# ColBERT 벡터 압축 저장\n",
    "with open('./embedding_result_v4/colbert_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_colbert, f)\n",
    "\n",
    "# float32 → float 로 강제 변환\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "serializable_sparse = convert_to_serializable(sparse_embeddings)\n",
    "\n",
    "with open('./embedding_result_v4/sparse_embeddings.json', 'w') as f:\n",
    "    json.dump(serializable_sparse, f, indent=2)\n",
    "    \n",
    "# 메타데이터 저장 (ColBERT 정보 추가)\n",
    "metadata = {\n",
    "    'keys': keys,\n",
    "    'texts': texts,\n",
    "    'colbert_shapes': [emb.shape for emb in processed_colbert]  # 원본 형태 정보\n",
    "}\n",
    "with open('./embedding_result_v4/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084bc37",
   "metadata": {},
   "source": [
    "# V2 - 사전 임베딩(영어) & 각 표현별 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3493f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 227951.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 51개의 텍스트를 임베딩합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "임베딩 생성:   0%|          | 0/2 [00:00<?, ?batch/s, batch=1/2, items=32]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "임베딩 생성: 100%|██████████| 2/2 [03:25<00:00, 102.56s/batch, batch=2/2, items=19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "임베딩 완료: 51개 벡터 생성\n",
      "ColBERT 벡터 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ColBERT 처리: 100%|██████████| 51/51 [00:00<00:00, 527.41vector/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "임베딩 결과 저장 중...\n",
      "Dense 임베딩 저장...\n",
      "ColBERT 임베딩 저장...\n",
      "Sparse 임베딩 변환 및 저장...\n",
      "메타데이터 저장...\n",
      "\n",
      "=== 임베딩 완료 ===\n",
      "- 총 텍스트 수: 51\n",
      "- Dense 임베딩 크기: (51, 1024)\n",
      "- Sparse 임베딩 수: 51\n",
      "- ColBERT 임베딩 수: 51\n",
      "- 배치 크기: 32\n",
      "- 저장 경로: ./embedding_result_v4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import json, pickle\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# 모델 초기화 (CPU/GPU 설정)\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "# 데이터 로드\n",
    "with open(\"../ServiceExtraction/integration/service_list_ver1.1.6.2.json\", \"r\") as f:\n",
    "    services = {}\n",
    "    data = json.load(f)\n",
    "    for device_id, device_info in data.items():\n",
    "        services[device_id] = \";\".join([expr for expr in device_info])\n",
    "\n",
    "keys = list(services.keys())\n",
    "texts = list(services.values())\n",
    "\n",
    "print(f\"총 {len(texts)}개의 텍스트를 임베딩합니다.\")\n",
    "\n",
    "# 임베딩 생성 (배치 처리 + tqdm)\n",
    "batch_size = 32\n",
    "total_batches = math.ceil(len(texts) / batch_size)\n",
    "\n",
    "dense_embeddings = []\n",
    "sparse_embeddings = []\n",
    "colbert_embeddings = []\n",
    "\n",
    "# tqdm으로 진행률 표시\n",
    "with tqdm(total=total_batches, desc=\"임베딩 생성\", unit=\"batch\") as pbar:\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        # 현재 배치 정보 업데이트\n",
    "        current_batch = i // batch_size + 1\n",
    "        pbar.set_postfix({\n",
    "            'batch': f\"{current_batch}/{total_batches}\",\n",
    "            'items': f\"{len(batch)}\"\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            outputs = model.encode(\n",
    "                batch, \n",
    "                return_dense=True,\n",
    "                return_sparse=True,\n",
    "                return_colbert_vecs=True\n",
    "            )\n",
    "            \n",
    "            dense_embeddings.extend(outputs['dense_vecs'])\n",
    "            sparse_embeddings.extend(outputs['lexical_weights'])\n",
    "            colbert_embeddings.extend(outputs['colbert_vecs'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n배치 {current_batch} 처리 중 오류 발생: {e}\")\n",
    "            continue\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "print(f\"\\n임베딩 완료: {len(dense_embeddings)}개 벡터 생성\")\n",
    "\n",
    "# ColBERT 벡터 저장 전처리\n",
    "def process_colbert(embeddings):\n",
    "    \"\"\"3D 배열을 저장 가능한 형태로 변환\"\"\"\n",
    "    print(\"ColBERT 벡터 처리 중...\")\n",
    "    processed = []\n",
    "    for emb in tqdm(embeddings, desc=\"ColBERT 처리\", unit=\"vector\"):\n",
    "        processed.append(emb.astype(np.float16))\n",
    "    return processed\n",
    "\n",
    "processed_colbert = process_colbert(colbert_embeddings)\n",
    "\n",
    "# 변환 함수\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.float16):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# 저장 (진행률 표시 포함)\n",
    "print(\"\\n임베딩 결과 저장 중...\")\n",
    "\n",
    "# Dense 임베딩 저장\n",
    "print(\"Dense 임베딩 저장...\")\n",
    "np.save('./embedding_result_v4/dense_embeddings.npy', np.array(dense_embeddings))\n",
    "\n",
    "# ColBERT 벡터 압축 저장\n",
    "print(\"ColBERT 임베딩 저장...\")\n",
    "with open('./embedding_result_v4/colbert_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_colbert, f)\n",
    "\n",
    "# Sparse 임베딩 저장\n",
    "print(\"Sparse 임베딩 변환 및 저장...\")\n",
    "serializable_sparse = convert_to_serializable(sparse_embeddings)\n",
    "\n",
    "with open('./embedding_result_v4/sparse_embeddings.json', 'w') as f:\n",
    "    json.dump(serializable_sparse, f, indent=2)\n",
    "\n",
    "# 메타데이터 저장\n",
    "print(\"메타데이터 저장...\")\n",
    "metadata = {\n",
    "    'keys': keys,\n",
    "    'texts': texts,\n",
    "    'total_count': len(texts),\n",
    "    'dense_shape': np.array(dense_embeddings).shape,\n",
    "    'colbert_shapes': [emb.shape for emb in processed_colbert],\n",
    "    'batch_size': batch_size\n",
    "}\n",
    "\n",
    "with open('./embedding_result_v4/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\n=== 임베딩 완료 ===\")\n",
    "print(f\"- 총 텍스트 수: {len(texts)}\")\n",
    "print(f\"- Dense 임베딩 크기: {np.array(dense_embeddings).shape}\")\n",
    "print(f\"- Sparse 임베딩 수: {len(sparse_embeddings)}\")\n",
    "print(f\"- ColBERT 임베딩 수: {len(processed_colbert)}\")\n",
    "print(f\"- 배치 크기: {batch_size}\")\n",
    "print(f\"- 저장 경로: ./embedding_result_v4/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea2c88e",
   "metadata": {},
   "source": [
    "# V3 - 사전 임베딩(영어) & 디바이스 이름 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569da4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 181833.99it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 적용된 표현 생성 중...\n",
      "AirConditioner: 114개 표현 (가중치 적용)\n",
      "AirPurifier: 72개 표현 (가중치 적용)\n",
      "AirQualityDetector: 86개 표현 (가중치 적용)\n",
      "Alarm: 88개 표현 (가중치 적용)\n",
      "Blind: 90개 표현 (가중치 적용)\n",
      "Button: 99개 표현 (가중치 적용)\n",
      "Buttonx4: 131개 표현 (가중치 적용)\n",
      "Calculator: 80개 표현 (가중치 적용)\n",
      "Camera: 91개 표현 (가중치 적용)\n",
      "Charger: 101개 표현 (가중치 적용)\n",
      "Clock: 121개 표현 (가중치 적용)\n",
      "ContactSensor: 81개 표현 (가중치 적용)\n",
      "Curtain: 72개 표현 (가중치 적용)\n",
      "Dehumidifier: 109개 표현 (가중치 적용)\n",
      "Dishwasher: 101개 표현 (가중치 적용)\n",
      "DoorLock: 88개 표현 (가중치 적용)\n",
      "EmailProvider: 87개 표현 (가중치 적용)\n",
      "Fan: 96개 표현 (가중치 적용)\n",
      "Feeder: 116개 표현 (가중치 적용)\n",
      "GasMeter: 74개 표현 (가중치 적용)\n",
      "GasValve: 69개 표현 (가중치 적용)\n",
      "Humidifier: 88개 표현 (가중치 적용)\n",
      "HumiditySensor: 80개 표현 (가중치 적용)\n",
      "Irrigator: 116개 표현 (가중치 적용)\n",
      "LeakSensor: 76개 표현 (가중치 적용)\n",
      "Light: 122개 표현 (가중치 적용)\n",
      "LightSensor: 75개 표현 (가중치 적용)\n",
      "MenuProvider: 76개 표현 (가중치 적용)\n",
      "MotionSensor: 79개 표현 (가중치 적용)\n",
      "PresenceSensor: 85개 표현 (가중치 적용)\n",
      "Pump: 104개 표현 (가중치 적용)\n",
      "Refrigerator: 101개 표현 (가중치 적용)\n",
      "RobotCleaner: 102개 표현 (가중치 적용)\n",
      "Shade: 102개 표현 (가중치 적용)\n",
      "Siren: 97개 표현 (가중치 적용)\n",
      "SmartPlug: 103개 표현 (가중치 적용)\n",
      "SmokeDetector: 85개 표현 (가중치 적용)\n",
      "SoilMoistureSensor: 73개 표현 (가중치 적용)\n",
      "SoundSensor: 99개 표현 (가중치 적용)\n",
      "Speaker: 121개 표현 (가중치 적용)\n",
      "Recorder: 99개 표현 (가중치 적용)\n",
      "Switch: 53개 표현 (가중치 적용)\n",
      "Television: 110개 표현 (가중치 적용)\n",
      "TemperatureSensor: 75개 표현 (가중치 적용)\n",
      "Valve: 71개 표현 (가중치 적용)\n",
      "WeatherProvider: 152개 표현 (가중치 적용)\n",
      "Window: 73개 표현 (가중치 적용)\n",
      "FallDetector: 74개 표현 (가중치 적용)\n",
      "OccupancySensor: 85개 표현 (가중치 적용)\n",
      "Relay: 53개 표현 (가중치 적용)\n",
      "Timer: 101개 표현 (가중치 적용)\n",
      "총 4696개의 표현을 임베딩합니다. (가중치 적용 후)\n",
      "배치 1/147 처리 중...\n",
      "배치 2/147 처리 중...\n",
      "배치 3/147 처리 중...\n",
      "배치 4/147 처리 중...\n",
      "배치 5/147 처리 중...\n",
      "배치 6/147 처리 중...\n",
      "배치 7/147 처리 중...\n",
      "배치 8/147 처리 중...\n",
      "배치 9/147 처리 중...\n",
      "배치 10/147 처리 중...\n",
      "배치 11/147 처리 중...\n",
      "배치 12/147 처리 중...\n",
      "배치 13/147 처리 중...\n",
      "배치 14/147 처리 중...\n",
      "배치 15/147 처리 중...\n",
      "배치 16/147 처리 중...\n",
      "배치 17/147 처리 중...\n",
      "배치 18/147 처리 중...\n",
      "배치 19/147 처리 중...\n",
      "배치 20/147 처리 중...\n",
      "배치 21/147 처리 중...\n",
      "배치 22/147 처리 중...\n",
      "배치 23/147 처리 중...\n",
      "배치 24/147 처리 중...\n",
      "배치 25/147 처리 중...\n",
      "배치 26/147 처리 중...\n",
      "배치 27/147 처리 중...\n",
      "배치 28/147 처리 중...\n",
      "배치 29/147 처리 중...\n",
      "배치 30/147 처리 중...\n",
      "배치 31/147 처리 중...\n",
      "배치 32/147 처리 중...\n",
      "배치 33/147 처리 중...\n",
      "배치 34/147 처리 중...\n",
      "배치 35/147 처리 중...\n",
      "배치 36/147 처리 중...\n",
      "배치 37/147 처리 중...\n",
      "배치 38/147 처리 중...\n",
      "배치 39/147 처리 중...\n",
      "배치 40/147 처리 중...\n",
      "배치 41/147 처리 중...\n",
      "배치 42/147 처리 중...\n",
      "배치 43/147 처리 중...\n",
      "배치 44/147 처리 중...\n",
      "배치 45/147 처리 중...\n",
      "배치 46/147 처리 중...\n",
      "배치 47/147 처리 중...\n",
      "배치 48/147 처리 중...\n",
      "배치 49/147 처리 중...\n",
      "배치 50/147 처리 중...\n",
      "배치 51/147 처리 중...\n",
      "배치 52/147 처리 중...\n",
      "배치 53/147 처리 중...\n",
      "배치 54/147 처리 중...\n",
      "배치 55/147 처리 중...\n",
      "배치 56/147 처리 중...\n",
      "배치 57/147 처리 중...\n",
      "배치 58/147 처리 중...\n",
      "배치 59/147 처리 중...\n",
      "배치 60/147 처리 중...\n",
      "배치 61/147 처리 중...\n",
      "배치 62/147 처리 중...\n",
      "배치 63/147 처리 중...\n",
      "배치 64/147 처리 중...\n",
      "배치 65/147 처리 중...\n",
      "배치 66/147 처리 중...\n",
      "배치 67/147 처리 중...\n",
      "배치 68/147 처리 중...\n",
      "배치 69/147 처리 중...\n",
      "배치 70/147 처리 중...\n",
      "배치 71/147 처리 중...\n",
      "배치 72/147 처리 중...\n",
      "배치 73/147 처리 중...\n",
      "배치 74/147 처리 중...\n",
      "배치 75/147 처리 중...\n",
      "배치 76/147 처리 중...\n",
      "배치 77/147 처리 중...\n",
      "배치 78/147 처리 중...\n",
      "배치 79/147 처리 중...\n",
      "배치 80/147 처리 중...\n",
      "배치 81/147 처리 중...\n",
      "배치 82/147 처리 중...\n",
      "배치 83/147 처리 중...\n",
      "배치 84/147 처리 중...\n",
      "배치 85/147 처리 중...\n",
      "배치 86/147 처리 중...\n",
      "배치 87/147 처리 중...\n",
      "배치 88/147 처리 중...\n",
      "배치 89/147 처리 중...\n",
      "배치 90/147 처리 중...\n",
      "배치 91/147 처리 중...\n",
      "배치 92/147 처리 중...\n",
      "배치 93/147 처리 중...\n",
      "배치 94/147 처리 중...\n",
      "배치 95/147 처리 중...\n",
      "배치 96/147 처리 중...\n",
      "배치 97/147 처리 중...\n",
      "배치 98/147 처리 중...\n",
      "배치 99/147 처리 중...\n",
      "배치 100/147 처리 중...\n",
      "배치 101/147 처리 중...\n",
      "배치 102/147 처리 중...\n",
      "배치 103/147 처리 중...\n",
      "배치 104/147 처리 중...\n",
      "배치 105/147 처리 중...\n",
      "배치 106/147 처리 중...\n",
      "배치 107/147 처리 중...\n",
      "배치 108/147 처리 중...\n",
      "배치 109/147 처리 중...\n",
      "배치 110/147 처리 중...\n",
      "배치 111/147 처리 중...\n",
      "배치 112/147 처리 중...\n",
      "배치 113/147 처리 중...\n",
      "배치 114/147 처리 중...\n",
      "배치 115/147 처리 중...\n",
      "배치 116/147 처리 중...\n",
      "배치 117/147 처리 중...\n",
      "배치 118/147 처리 중...\n",
      "배치 119/147 처리 중...\n",
      "배치 120/147 처리 중...\n",
      "배치 121/147 처리 중...\n",
      "배치 122/147 처리 중...\n",
      "배치 123/147 처리 중...\n",
      "배치 124/147 처리 중...\n",
      "배치 125/147 처리 중...\n",
      "배치 126/147 처리 중...\n",
      "배치 127/147 처리 중...\n",
      "배치 128/147 처리 중...\n",
      "배치 129/147 처리 중...\n",
      "배치 130/147 처리 중...\n",
      "배치 131/147 처리 중...\n",
      "배치 132/147 처리 중...\n",
      "배치 133/147 처리 중...\n",
      "배치 134/147 처리 중...\n",
      "배치 135/147 처리 중...\n",
      "배치 136/147 처리 중...\n",
      "배치 137/147 처리 중...\n",
      "배치 138/147 처리 중...\n",
      "배치 139/147 처리 중...\n",
      "배치 140/147 처리 중...\n",
      "배치 141/147 처리 중...\n",
      "배치 142/147 처리 중...\n",
      "배치 143/147 처리 중...\n",
      "배치 144/147 처리 중...\n",
      "배치 145/147 처리 중...\n",
      "배치 146/147 처리 중...\n",
      "배치 147/147 처리 중...\n",
      "임베딩 결과 저장 중...\n",
      "\n",
      "=== 임베딩 완료 ===\n",
      "- 총 표현 수: 4696 (가중치 적용 후)\n",
      "- 기기 종류 수: 51\n",
      "- Dense 임베딩 크기: (4696, 1024)\n",
      "\n",
      "=== 기기별 가중치 적용 결과 ===\n",
      "AirConditioner: 102 → 114 (x1.1)\n",
      "AirPurifier: 60 → 72 (x1.2)\n",
      "AirQualityDetector: 70 → 86 (x1.2)\n",
      "Alarm: 68 → 88 (x1.3)\n",
      "Blind: 74 → 90 (x1.2)\n",
      "Button: 91 → 99 (x1.1)\n",
      "Buttonx4: 115 → 131 (x1.1)\n",
      "Calculator: 76 → 80 (x1.1)\n",
      "Camera: 67 → 91 (x1.4)\n",
      "Charger: 81 → 101 (x1.2)\n",
      "Clock: 109 → 121 (x1.1)\n",
      "ContactSensor: 69 → 81 (x1.2)\n",
      "Curtain: 56 → 72 (x1.3)\n",
      "Dehumidifier: 97 → 109 (x1.1)\n",
      "Dishwasher: 85 → 101 (x1.2)\n",
      "DoorLock: 68 → 88 (x1.3)\n",
      "EmailProvider: 71 → 87 (x1.2)\n",
      "Fan: 76 → 96 (x1.3)\n",
      "Feeder: 88 → 116 (x1.3)\n",
      "GasMeter: 50 → 74 (x1.5)\n",
      "GasValve: 53 → 69 (x1.3)\n",
      "Humidifier: 68 → 88 (x1.3)\n",
      "HumiditySensor: 52 → 80 (x1.5)\n",
      "Irrigator: 92 → 116 (x1.3)\n",
      "LeakSensor: 56 → 76 (x1.4)\n",
      "Light: 102 → 122 (x1.2)\n",
      "LightSensor: 55 → 75 (x1.4)\n",
      "MenuProvider: 72 → 76 (x1.1)\n",
      "MotionSensor: 63 → 79 (x1.3)\n",
      "PresenceSensor: 61 → 85 (x1.4)\n",
      "Pump: 88 → 104 (x1.2)\n",
      "Refrigerator: 81 → 101 (x1.2)\n",
      "RobotCleaner: 82 → 102 (x1.2)\n",
      "Shade: 82 → 102 (x1.2)\n",
      "Siren: 73 → 97 (x1.3)\n",
      "SmartPlug: 83 → 103 (x1.2)\n",
      "SmokeDetector: 61 → 85 (x1.4)\n",
      "SoilMoistureSensor: 53 → 73 (x1.4)\n",
      "SoundSensor: 79 → 99 (x1.3)\n",
      "Speaker: 97 → 121 (x1.2)\n",
      "Recorder: 75 → 99 (x1.3)\n",
      "Switch: 49 → 53 (x1.1)\n",
      "Television: 90 → 110 (x1.2)\n",
      "TemperatureSensor: 55 → 75 (x1.4)\n",
      "Valve: 55 → 71 (x1.3)\n",
      "WeatherProvider: 128 → 152 (x1.2)\n",
      "Window: 57 → 73 (x1.3)\n",
      "FallDetector: 54 → 74 (x1.4)\n",
      "OccupancySensor: 61 → 85 (x1.4)\n",
      "Relay: 49 → 53 (x1.1)\n",
      "Timer: 77 → 101 (x1.3)\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import json, pickle\n",
    "\n",
    "# 모델 초기화 (CPU/GPU 설정)\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "# 새로운 구조의 디바이스 정의 파일 로드\n",
    "with open(\"../ServiceExtraction/integration/service_list_ver1.1.6.3.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    device_definitions = json.load(f)\n",
    "\n",
    "# 가중치 설정\n",
    "def create_weighted_expressions(device_data, name_weight=5, expr_weight=1):\n",
    "    \"\"\"names는 높은 가중치, expressions는 기본 가중치\"\"\"\n",
    "    weighted_list = []\n",
    "    \n",
    "    # names: 높은 가중치 (중복 삽입)\n",
    "    if \"names\" in device_data:\n",
    "        for name in device_data[\"names\"]:\n",
    "            weighted_list.extend([name] * name_weight)\n",
    "    \n",
    "    # expressions: 기본 가중치\n",
    "    if \"expressions\" in device_data:\n",
    "        for expr in device_data[\"expressions\"]:\n",
    "            weighted_list.extend([expr] * expr_weight)\n",
    "    \n",
    "    return weighted_list\n",
    "\n",
    "# 가중치가 적용된 표현 리스트 생성\n",
    "device_expressions_weighted = {}\n",
    "print(\"가중치 적용된 표현 생성 중...\")\n",
    "\n",
    "for device_type, device_data in device_definitions.items():\n",
    "    weighted_expressions = create_weighted_expressions(device_data)\n",
    "    device_expressions_weighted[device_type] = weighted_expressions\n",
    "    print(f\"{device_type}: {len(weighted_expressions)}개 표현 (가중치 적용)\")\n",
    "\n",
    "# 각 표현별로 메타데이터 생성 (수정된 부분)\n",
    "all_texts = []\n",
    "all_metadata = []\n",
    "\n",
    "for device_type, expressions in device_expressions_weighted.items():  # 수정: device_expressions → device_expressions_weighted\n",
    "    for expression in expressions:\n",
    "        all_texts.append(expression)\n",
    "        all_metadata.append({\n",
    "            \"device_type\": device_type,\n",
    "            \"expression\": expression,\n",
    "            \"device_id\": f\"{device_type}_{len(all_metadata)}\",\n",
    "            \"is_weighted\": True\n",
    "        })\n",
    "\n",
    "print(f\"총 {len(all_texts)}개의 표현을 임베딩합니다. (가중치 적용 후)\")\n",
    "\n",
    "# 임베딩 생성 (배치 처리)\n",
    "batch_size = 32\n",
    "dense_embeddings = []\n",
    "sparse_embeddings = []\n",
    "colbert_embeddings = []\n",
    "\n",
    "for i in range(0, len(all_texts), batch_size):\n",
    "    batch = all_texts[i:i+batch_size]\n",
    "    print(f\"배치 {i//batch_size + 1}/{(len(all_texts)-1)//batch_size + 1} 처리 중...\")\n",
    "    \n",
    "    outputs = model.encode(\n",
    "        batch, \n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=True\n",
    "    )\n",
    "    \n",
    "    dense_embeddings.extend(outputs['dense_vecs'])\n",
    "    sparse_embeddings.extend(outputs['lexical_weights'])\n",
    "    colbert_embeddings.extend(outputs['colbert_vecs'])\n",
    "\n",
    "# ColBERT 벡터 저장 전처리\n",
    "def process_colbert(embeddings):\n",
    "    \"\"\"3D 배열을 저장 가능한 형태로 변환\"\"\"\n",
    "    return [emb.astype(np.float16) for emb in embeddings]\n",
    "\n",
    "processed_colbert = process_colbert(colbert_embeddings)\n",
    "\n",
    "# 변환 함수\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.float16):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# 저장\n",
    "print(\"임베딩 결과 저장 중...\")\n",
    "\n",
    "# Dense 임베딩 저장\n",
    "np.save('./embedding_result_v3/dense_embeddings.npy', np.array(dense_embeddings))\n",
    "\n",
    "# ColBERT 벡터 압축 저장\n",
    "with open('./embedding_result_v3/colbert_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_colbert, f)\n",
    "\n",
    "# Sparse 임베딩 저장 (경로 수정)\n",
    "serializable_sparse = convert_to_serializable(sparse_embeddings)\n",
    "with open('./embedding_result_v3/sparse_embeddings.json', 'w', encoding='utf-8') as f:  # 수정: 경로 통일\n",
    "    json.dump(serializable_sparse, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# 메타데이터 저장 (경로 수정)\n",
    "metadata = {\n",
    "    'total_expressions': len(all_texts),\n",
    "    'expressions': all_texts,\n",
    "    'metadata': all_metadata,\n",
    "    'device_types': list(device_expressions_weighted.keys()),\n",
    "    'colbert_shapes': [emb.shape for emb in processed_colbert],\n",
    "    'weighted_counts': {device: len(exprs) for device, exprs in device_expressions_weighted.items()}\n",
    "}\n",
    "\n",
    "with open('./embedding_result_v3/metadata.json', 'w', encoding='utf-8') as f:  # 수정: 경로 통일\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# 기기별 인덱스 매핑 저장 (경로 수정)\n",
    "device_index_mapping = {}\n",
    "for idx, meta in enumerate(all_metadata):\n",
    "    device_type = meta['device_type']\n",
    "    if device_type not in device_index_mapping:\n",
    "        device_index_mapping[device_type] = []\n",
    "    device_index_mapping[device_type].append(idx)\n",
    "\n",
    "with open('./embedding_result_v3/device_index_mapping.json', 'w', encoding='utf-8') as f:  # 수정: 경로 통일\n",
    "    json.dump(device_index_mapping, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# 가중치 적용 통계 출력\n",
    "print(\"\\n=== 임베딩 완료 ===\")\n",
    "print(f\"- 총 표현 수: {len(all_texts)} (가중치 적용 후)\")\n",
    "print(f\"- 기기 종류 수: {len(device_expressions_weighted)}\")\n",
    "print(f\"- Dense 임베딩 크기: {np.array(dense_embeddings).shape}\")\n",
    "\n",
    "print(\"\\n=== 기기별 가중치 적용 결과 ===\")\n",
    "for device_type, count in metadata['weighted_counts'].items():\n",
    "    original_count = len(device_definitions.get(device_type, {}).get('names', [])) + len(device_definitions.get(device_type, {}).get('expressions', []))\n",
    "    weight_ratio = count / original_count if original_count > 0 else 0\n",
    "    print(f\"{device_type}: {original_count} → {count} (x{weight_ratio:.1f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3fd4ed",
   "metadata": {},
   "source": [
    "# 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1592321",
   "metadata": {},
   "source": [
    "##  dense_vecs (문장 전체 평균)만 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb727ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 149796.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json, pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 임베딩 데이터 로드\n",
    "dense_embeddings = np.load('./embedding_result_v1/dense_embeddings.npy')\n",
    "with open('./embedding_result_v1/sparse_embeddings.json') as f:\n",
    "    sparse_embeddings = json.load(f)\n",
    "with open('./embedding_result_v1/metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# 모델 초기화 (CPU 전용)\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cbf3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 서비스 (쿼리: '기온이 30도 이상이면 커튼을 닫고 에어컨을 틀어줘'):\n",
      "1. AirConditioner (유사도: 0.6530)\n",
      "   내용: 에어컨은 냉방, 난방, 제습, 송풍 등 다양한 모드로 실내 온도와 습도를 조절하는 기기입니...\n",
      "2. Curtain (유사도: 0.6228)\n",
      "   내용: 커튼은 열고 닫고 멈추는 기능을 가진 장치로, 햇빛 조절이나 사생활 보호를 위해 사용됩니다...\n",
      "3. Blind (유사도: 0.5736)\n",
      "   내용: 블라인드(커튼)는 창문을 덮거나 열어 햇빛의 양을 조절하고 사생활을 보호하는 장치입니다. ...\n",
      "4. TemperatureSensor (유사도: 0.5592)\n",
      "   내용: 온도 센서는 현재 환경의 온도를 측정하여 수치로 제공합니다. 주로 특정 온도 조건에 따라 ...\n",
      "5. Humidifier (유사도: 0.5570)\n",
      "   내용: 가습기는 실내 습도를 조절해주는 장치로, 전원을 켜고 끌 수 있으며 자동, 약풍, 중간, ...\n",
      "6. Fan (유사도: 0.5387)\n",
      "   내용: 선풍기나 환풍기 등의 팬 장치는 전원을 켜고 끌 수 있으며, 풍속을 RPM이나 퍼센트로 조...\n",
      "7. WeatherProvider (유사도: 0.5333)\n",
      "   내용: 날씨 제공 장치는 현재 기온, 습도, 기압, 미세먼지 수치, 날씨 상태 등을 바탕으로 자동...\n",
      "8. DoorLock (유사도: 0.5332)\n",
      "   내용: 도어락은 문을 원격으로 열고 닫을 수 있는 기기로, 현재 문이 열려 있는지 닫혀 있는지도 ...\n",
      "9. AirPurifier (유사도: 0.5262)\n",
      "   내용: 공기청정기는 실내 공기 중의 먼지, 미세먼지, 냄새 등을 줄여 쾌적한 환경을 만들어 주는 ...\n",
      "10. Window (유사도: 0.5209)\n",
      "   내용: 창문은 열림, 닫힘, 또는 상태를 알 수 없는 상태로 존재하며, 환기나 보안, 환경 조건에...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recommend_services(query, top_k=10):\n",
    "    # 쿼리 임베딩 생성\n",
    "    query_dense = model.encode([query], return_dense=True)['dense_vecs'][0]\n",
    "    \n",
    "    # 유사도 계산\n",
    "    dense_scores = cosine_similarity([query_dense], dense_embeddings)[0]\n",
    "    \n",
    "    # 상위 K개 결과 추출\n",
    "    top_indices = np.argsort(dense_scores)[-top_k:][::-1]\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            'key': metadata['keys'][i],\n",
    "            'text': metadata['texts'][i],\n",
    "            'score': float(dense_scores[i])\n",
    "        }\n",
    "        for i in top_indices\n",
    "    ]\n",
    "\n",
    "# 사용자 입력 처리\n",
    "user_query = \"기온이 30도 이상이면 커튼을 닫고 에어컨을 틀어줘\"\n",
    "results = recommend_services(user_query)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"추천 서비스 (쿼리: '{user_query}'):\")\n",
    "for idx, result in enumerate(results, 1):\n",
    "    print(f\"{idx}. {result['key']} (유사도: {result['score']:.4f})\")\n",
    "    print(f\"   내용: {result['text'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622cb53",
   "metadata": {},
   "source": [
    "## colbert_vecs를 활용한 dense token-level 다중 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 181309.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json, pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "# 모델 및 데이터 초기화\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=False)  # CPU 환경\n",
    "\n",
    "# 임베딩 데이터 로드 (ColBERT 추가)\n",
    "dense_embeddings = np.load('./embedding_result_v1/dense_embeddings.npy')\n",
    "# colbert_data = np.load('./embedding_result_v1/colbert_embeddings.npz', allow_pickle=True)\n",
    "# colbert_embeddings = [emb.astype(np.float32) for emb in colbert_data['colbert']]  # float32로 변환\n",
    "with open('./embedding_result_v1/colbert_embeddings.pkl', 'rb') as f:\n",
    "    colbert_embeddings = pickle.load(f)\n",
    "\n",
    "with open('./embedding_result_v1/sparse_embeddings.json') as f:\n",
    "    sparse_embeddings = json.load(f)\n",
    "    \n",
    "with open('./embedding_result_v1/metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af3d279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColBERT 유사도 계산 함수\n",
    "# 1) 평균 맥스심 점수\n",
    "def colbert_maxsim(query_vec, doc_vecs):\n",
    "    \"\"\"\n",
    "    query_vec: [query_tokens, dim]\n",
    "    doc_vecs: [doc_tokens, dim]\n",
    "    \"\"\"\n",
    "    sim_matrix = cosine_similarity(query_vec, doc_vecs)\n",
    "    return np.max(sim_matrix, axis=1).mean()  \n",
    "\n",
    "# 2) Softmax MaxSim\n",
    "def colbert_softmax_maxsim(query_vec, doc_vecs, temperature=0.05):\n",
    "    sim_matrix = cosine_similarity(query_vec, doc_vecs)\n",
    "    max_sim = np.max(sim_matrix, axis=1)\n",
    "    weights = np.exp(max_sim / temperature)\n",
    "    weights /= np.sum(weights)\n",
    "    return np.sum(weights * max_sim)\n",
    "\n",
    "# 하이브리드 추천 함수\n",
    "def hybrid_recommend(query, top_k=10, max_k=15, weights=(0.6, 0.3, 0.1)):\n",
    "    # 쿼리 임베딩 생성\n",
    "    query_emb = model.encode(\n",
    "        [query], \n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=True\n",
    "    )\n",
    "    \n",
    "    # 각 유사도 계산\n",
    "    dense_scores = cosine_similarity([query_emb['dense_vecs'][0]], dense_embeddings)[0]\n",
    "    \n",
    "    sparse_scores = []\n",
    "    query_weights = query_emb['lexical_weights'][0]  # dict\n",
    "\n",
    "    for doc_weights in sparse_embeddings:  # 문서별 sparse dict\n",
    "        score = sum(query_weights.get(token, 0) * doc_weights.get(token, 0) for token in query_weights)\n",
    "        sparse_scores.append(score)\n",
    "    \n",
    "    colbert_scores = [\n",
    "        colbert_softmax_maxsim(query_emb['colbert_vecs'][0], doc_emb)\n",
    "        for doc_emb in colbert_embeddings\n",
    "    ]\n",
    "    \n",
    "    # 점수 정규화 및 결합\n",
    "    max_score = max(dense_scores.max(), 1e-6)\n",
    "    combined_scores = (\n",
    "        weights[0] * dense_scores/max_score +\n",
    "        weights[1] * np.array(sparse_scores) +\n",
    "        weights[2] * np.array(colbert_scores)\n",
    "    )\n",
    "    \n",
    "    # # 상위 K개 추출\n",
    "    # top_indices = np.argsort(combined_scores)[-top_k:][::-1]\n",
    "\n",
    "    # 유사 결과 많을 경우 확장\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "\n",
    "    gap_threshold = 0.01\n",
    "    initial_top = 5\n",
    "    top_indices = [sorted_indices[0]]\n",
    "\n",
    "    for i in range(1, len(sorted_indices)):\n",
    "        if len(top_indices) >= max_k:\n",
    "            break\n",
    "        prev = combined_scores[top_indices[-1]]\n",
    "        curr = combined_scores[sorted_indices[i]]\n",
    "        if curr >= 0.5 or abs(prev - curr) <= gap_threshold or len(top_indices) < initial_top:\n",
    "            top_indices.append(sorted_indices[i])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return [{\n",
    "        'key': metadata['keys'][i],\n",
    "        'text': metadata['texts'][i],\n",
    "        'dense_score': float(dense_scores[i]),\n",
    "        'sparse_score': float(sparse_scores[i]),\n",
    "        'colbert_score': float(colbert_scores[i]),\n",
    "        'combined_score': float(combined_scores[i])\n",
    "    } for i in top_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdf7da44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 서비스:\n",
      "1. AirPurifier\n",
      "   종합 점수: 0.7494\n",
      "   Dense: 0.703, Sparse: 0.272, ColBERT: 0.793\n",
      "2. AirConditioner\n",
      "   종합 점수: 0.7357\n",
      "   Dense: 0.717, Sparse: 0.185, ColBERT: 0.802\n",
      "3. Curtain\n",
      "   종합 점수: 0.7140\n",
      "   Dense: 0.693, Sparse: 0.178, ColBERT: 0.809\n",
      "4. WeatherProvider\n",
      "   종합 점수: 0.6962\n",
      "   Dense: 0.659, Sparse: 0.218, ColBERT: 0.791\n",
      "5. AirQualityDetector\n",
      "   종합 점수: 0.6761\n",
      "   Dense: 0.629, Sparse: 0.231, ColBERT: 0.801\n",
      "6. Blind\n",
      "   종합 점수: 0.6617\n",
      "   Dense: 0.628, Sparse: 0.186, ColBERT: 0.798\n",
      "7. TemperatureSensor\n",
      "   종합 점수: 0.6356\n",
      "   Dense: 0.620, Sparse: 0.114, ColBERT: 0.824\n",
      "8. Humidifier\n",
      "   종합 점수: 0.6317\n",
      "   Dense: 0.639, Sparse: 0.056, ColBERT: 0.804\n",
      "9. Window\n",
      "   종합 점수: 0.6238\n",
      "   Dense: 0.619, Sparse: 0.082, ColBERT: 0.809\n",
      "10. Dehumidifier\n",
      "   종합 점수: 0.6005\n",
      "   Dense: 0.589, Sparse: 0.093, ColBERT: 0.796\n",
      "11. DoorLock\n",
      "   종합 점수: 0.5989\n",
      "   Dense: 0.563, Sparse: 0.154, ColBERT: 0.816\n",
      "12. Pump\n",
      "   종합 점수: 0.5944\n",
      "   Dense: 0.575, Sparse: 0.116, ColBERT: 0.782\n",
      "13. Fan\n",
      "   종합 점수: 0.5797\n",
      "   Dense: 0.574, Sparse: 0.074, ColBERT: 0.772\n",
      "14. ContactSensor\n",
      "   종합 점수: 0.5771\n",
      "   Dense: 0.570, Sparse: 0.062, ColBERT: 0.813\n",
      "15. Shade\n",
      "   종합 점수: 0.5747\n",
      "   Dense: 0.562, Sparse: 0.076, ColBERT: 0.817\n"
     ]
    }
   ],
   "source": [
    "# 추천 실행\n",
    "results = hybrid_recommend(\n",
    "    \"날씨가 맑고, 기온이 30도 이상이면 커튼을 닫고 에어컨을 틀고, 미세먼지가 나쁘면 창문을 닫고 공기청정기를 켜줘.\", \n",
    "    top_k=10)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"추천 서비스:\")\n",
    "for idx, item in enumerate(results, 1):\n",
    "    print(f\"{idx}. {item['key']}\")\n",
    "    print(f\"   종합 점수: {item['combined_score']:.4f}\")\n",
    "    print(f\"   Dense: {item['dense_score']:.3f}, Sparse: {item['sparse_score']:.3f}, ColBERT: {item['colbert_score']:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
