{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50917aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install FlagEmbedding pymilvus \"pymilvus[model]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b06c8",
   "metadata": {},
   "source": [
    "# 사전 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a75f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/endermaru/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files: 100%|██████████| 30/30 [09:40<00:00, 19.33s/it]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import json, pickle\n",
    "\n",
    "# 모델 초기화 (CPU/GPU 설정)\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "# with open(\"../ServiceExtraction/integration/0.1.5_embedding_all.json\", \"r\") as f:\n",
    "#     services = json.load(f)\n",
    "\n",
    "with open(\"../ServiceExtraction/integration/service_list_ver1.1.6.json\", \"r\") as f:\n",
    "    services = {}\n",
    "    data = json.load(f)\n",
    "    for device_id, device_info in data.items():\n",
    "        services[device_id] = f\"{device_info[\"info\"]}; {\";\".join(device_info[\"examples\"])}\"\n",
    "    # print(services)\n",
    "\n",
    "keys = list(services.keys())\n",
    "texts = list(services.values())\n",
    "\n",
    "# 임베딩 생성 (배치 처리)\n",
    "batch_size = 32\n",
    "dense_embeddings = []\n",
    "sparse_embeddings = []\n",
    "colbert_embeddings = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    outputs = model.encode(\n",
    "        batch, \n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=True  # ColBERT 활성화\n",
    "    )\n",
    "    dense_embeddings.extend(outputs['dense_vecs'])\n",
    "    sparse_embeddings.extend(outputs['lexical_weights'])\n",
    "    colbert_embeddings.extend(outputs['colbert_vecs'])\n",
    "\n",
    "# ColBERT 벡터 저장 전처리\n",
    "def process_colbert(embeddings):\n",
    "    \"\"\"3D 배열을 저장 가능한 형태로 변환\"\"\"\n",
    "    return [emb.astype(np.float16) for emb in embeddings]  # 절반의 저장 공간 절약\n",
    "\n",
    "processed_colbert = process_colbert(colbert_embeddings)\n",
    "\n",
    "# 변환 함수 확장\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.float16):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# 저장\n",
    "np.save('./embedding_result/dense_embeddings.npy', np.array(dense_embeddings))\n",
    "# ColBERT 벡터 압축 저장\n",
    "with open('./embedding_result/colbert_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_colbert, f)\n",
    "\n",
    "# float32 → float 로 강제 변환\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "serializable_sparse = convert_to_serializable(sparse_embeddings)\n",
    "\n",
    "with open('./embedding_result/sparse_embeddings.json', 'w') as f:\n",
    "    json.dump(serializable_sparse, f, indent=2)\n",
    "    \n",
    "# 메타데이터 저장 (ColBERT 정보 추가)\n",
    "metadata = {\n",
    "    'keys': keys,\n",
    "    'texts': texts,\n",
    "    'colbert_shapes': [emb.shape for emb in processed_colbert]  # 원본 형태 정보\n",
    "}\n",
    "with open('./embedding_result/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3fd4ed",
   "metadata": {},
   "source": [
    "# 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1592321",
   "metadata": {},
   "source": [
    "##  dense_vecs (문장 전체 평균)만 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb727ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 149796.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json, pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 임베딩 데이터 로드\n",
    "dense_embeddings = np.load('./embedding_result/dense_embeddings.npy')\n",
    "with open('./embedding_result/sparse_embeddings.json') as f:\n",
    "    sparse_embeddings = json.load(f)\n",
    "with open('./embedding_result/metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# 모델 초기화 (CPU 전용)\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cbf3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 서비스 (쿼리: '기온이 30도 이상이면 커튼을 닫고 에어컨을 틀어줘'):\n",
      "1. AirConditioner (유사도: 0.6530)\n",
      "   내용: 에어컨은 냉방, 난방, 제습, 송풍 등 다양한 모드로 실내 온도와 습도를 조절하는 기기입니...\n",
      "2. Curtain (유사도: 0.6228)\n",
      "   내용: 커튼은 열고 닫고 멈추는 기능을 가진 장치로, 햇빛 조절이나 사생활 보호를 위해 사용됩니다...\n",
      "3. Blind (유사도: 0.5736)\n",
      "   내용: 블라인드(커튼)는 창문을 덮거나 열어 햇빛의 양을 조절하고 사생활을 보호하는 장치입니다. ...\n",
      "4. TemperatureSensor (유사도: 0.5592)\n",
      "   내용: 온도 센서는 현재 환경의 온도를 측정하여 수치로 제공합니다. 주로 특정 온도 조건에 따라 ...\n",
      "5. Humidifier (유사도: 0.5570)\n",
      "   내용: 가습기는 실내 습도를 조절해주는 장치로, 전원을 켜고 끌 수 있으며 자동, 약풍, 중간, ...\n",
      "6. Fan (유사도: 0.5387)\n",
      "   내용: 선풍기나 환풍기 등의 팬 장치는 전원을 켜고 끌 수 있으며, 풍속을 RPM이나 퍼센트로 조...\n",
      "7. WeatherProvider (유사도: 0.5333)\n",
      "   내용: 날씨 제공 장치는 현재 기온, 습도, 기압, 미세먼지 수치, 날씨 상태 등을 바탕으로 자동...\n",
      "8. DoorLock (유사도: 0.5332)\n",
      "   내용: 도어락은 문을 원격으로 열고 닫을 수 있는 기기로, 현재 문이 열려 있는지 닫혀 있는지도 ...\n",
      "9. AirPurifier (유사도: 0.5262)\n",
      "   내용: 공기청정기는 실내 공기 중의 먼지, 미세먼지, 냄새 등을 줄여 쾌적한 환경을 만들어 주는 ...\n",
      "10. Window (유사도: 0.5209)\n",
      "   내용: 창문은 열림, 닫힘, 또는 상태를 알 수 없는 상태로 존재하며, 환기나 보안, 환경 조건에...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recommend_services(query, top_k=10):\n",
    "    # 쿼리 임베딩 생성\n",
    "    query_dense = model.encode([query], return_dense=True)['dense_vecs'][0]\n",
    "    \n",
    "    # 유사도 계산\n",
    "    dense_scores = cosine_similarity([query_dense], dense_embeddings)[0]\n",
    "    \n",
    "    # 상위 K개 결과 추출\n",
    "    top_indices = np.argsort(dense_scores)[-top_k:][::-1]\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            'key': metadata['keys'][i],\n",
    "            'text': metadata['texts'][i],\n",
    "            'score': float(dense_scores[i])\n",
    "        }\n",
    "        for i in top_indices\n",
    "    ]\n",
    "\n",
    "# 사용자 입력 처리\n",
    "user_query = \"기온이 30도 이상이면 커튼을 닫고 에어컨을 틀어줘\"\n",
    "results = recommend_services(user_query)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"추천 서비스 (쿼리: '{user_query}'):\")\n",
    "for idx, result in enumerate(results, 1):\n",
    "    print(f\"{idx}. {result['key']} (유사도: {result['score']:.4f})\")\n",
    "    print(f\"   내용: {result['text'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622cb53",
   "metadata": {},
   "source": [
    "## colbert_vecs를 활용한 dense token-level 다중 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb87a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 181309.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json, pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "# 모델 및 데이터 초기화\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=False)  # CPU 환경\n",
    "\n",
    "# 임베딩 데이터 로드 (ColBERT 추가)\n",
    "dense_embeddings = np.load('./embedding_result/dense_embeddings.npy')\n",
    "# colbert_data = np.load('./embedding_result/colbert_embeddings.npz', allow_pickle=True)\n",
    "# colbert_embeddings = [emb.astype(np.float32) for emb in colbert_data['colbert']]  # float32로 변환\n",
    "with open('./embedding_result/colbert_embeddings.pkl', 'rb') as f:\n",
    "    colbert_embeddings = pickle.load(f)\n",
    "\n",
    "with open('./embedding_result/sparse_embeddings.json') as f:\n",
    "    sparse_embeddings = json.load(f)\n",
    "    \n",
    "with open('./embedding_result/metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af3d279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColBERT 유사도 계산 함수\n",
    "# 1) 평균 맥스심 점수\n",
    "def colbert_maxsim(query_vec, doc_vecs):\n",
    "    \"\"\"\n",
    "    query_vec: [query_tokens, dim]\n",
    "    doc_vecs: [doc_tokens, dim]\n",
    "    \"\"\"\n",
    "    sim_matrix = cosine_similarity(query_vec, doc_vecs)\n",
    "    return np.max(sim_matrix, axis=1).mean()  \n",
    "\n",
    "# 2) Softmax MaxSim\n",
    "def colbert_softmax_maxsim(query_vec, doc_vecs, temperature=0.05):\n",
    "    sim_matrix = cosine_similarity(query_vec, doc_vecs)\n",
    "    max_sim = np.max(sim_matrix, axis=1)\n",
    "    weights = np.exp(max_sim / temperature)\n",
    "    weights /= np.sum(weights)\n",
    "    return np.sum(weights * max_sim)\n",
    "\n",
    "# 하이브리드 추천 함수\n",
    "def hybrid_recommend(query, top_k=10, max_k=15, weights=(0.6, 0.3, 0.1)):\n",
    "    # 쿼리 임베딩 생성\n",
    "    query_emb = model.encode(\n",
    "        [query], \n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=True\n",
    "    )\n",
    "    \n",
    "    # 각 유사도 계산\n",
    "    dense_scores = cosine_similarity([query_emb['dense_vecs'][0]], dense_embeddings)[0]\n",
    "    \n",
    "    sparse_scores = []\n",
    "    query_weights = query_emb['lexical_weights'][0]  # dict\n",
    "\n",
    "    for doc_weights in sparse_embeddings:  # 문서별 sparse dict\n",
    "        score = sum(query_weights.get(token, 0) * doc_weights.get(token, 0) for token in query_weights)\n",
    "        sparse_scores.append(score)\n",
    "    \n",
    "    colbert_scores = [\n",
    "        colbert_softmax_maxsim(query_emb['colbert_vecs'][0], doc_emb)\n",
    "        for doc_emb in colbert_embeddings\n",
    "    ]\n",
    "    \n",
    "    # 점수 정규화 및 결합\n",
    "    max_score = max(dense_scores.max(), 1e-6)\n",
    "    combined_scores = (\n",
    "        weights[0] * dense_scores/max_score +\n",
    "        weights[1] * np.array(sparse_scores) +\n",
    "        weights[2] * np.array(colbert_scores)\n",
    "    )\n",
    "    \n",
    "    # # 상위 K개 추출\n",
    "    # top_indices = np.argsort(combined_scores)[-top_k:][::-1]\n",
    "\n",
    "    # 유사 결과 많을 경우 확장\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "\n",
    "    gap_threshold = 0.01\n",
    "    initial_top = 5\n",
    "    top_indices = [sorted_indices[0]]\n",
    "\n",
    "    for i in range(1, len(sorted_indices)):\n",
    "        if len(top_indices) >= max_k:\n",
    "            break\n",
    "        prev = combined_scores[top_indices[-1]]\n",
    "        curr = combined_scores[sorted_indices[i]]\n",
    "        if curr >= 0.5 or abs(prev - curr) <= gap_threshold or len(top_indices) < initial_top:\n",
    "            top_indices.append(sorted_indices[i])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return [{\n",
    "        'key': metadata['keys'][i],\n",
    "        'text': metadata['texts'][i],\n",
    "        'dense_score': float(dense_scores[i]),\n",
    "        'sparse_score': float(sparse_scores[i]),\n",
    "        'colbert_score': float(colbert_scores[i]),\n",
    "        'combined_score': float(combined_scores[i])\n",
    "    } for i in top_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdf7da44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 서비스:\n",
      "1. AirPurifier\n",
      "   종합 점수: 0.7494\n",
      "   Dense: 0.703, Sparse: 0.272, ColBERT: 0.793\n",
      "2. AirConditioner\n",
      "   종합 점수: 0.7357\n",
      "   Dense: 0.717, Sparse: 0.185, ColBERT: 0.802\n",
      "3. Curtain\n",
      "   종합 점수: 0.7140\n",
      "   Dense: 0.693, Sparse: 0.178, ColBERT: 0.809\n",
      "4. WeatherProvider\n",
      "   종합 점수: 0.6962\n",
      "   Dense: 0.659, Sparse: 0.218, ColBERT: 0.791\n",
      "5. AirQualityDetector\n",
      "   종합 점수: 0.6761\n",
      "   Dense: 0.629, Sparse: 0.231, ColBERT: 0.801\n",
      "6. Blind\n",
      "   종합 점수: 0.6617\n",
      "   Dense: 0.628, Sparse: 0.186, ColBERT: 0.798\n",
      "7. TemperatureSensor\n",
      "   종합 점수: 0.6356\n",
      "   Dense: 0.620, Sparse: 0.114, ColBERT: 0.824\n",
      "8. Humidifier\n",
      "   종합 점수: 0.6317\n",
      "   Dense: 0.639, Sparse: 0.056, ColBERT: 0.804\n",
      "9. Window\n",
      "   종합 점수: 0.6238\n",
      "   Dense: 0.619, Sparse: 0.082, ColBERT: 0.809\n",
      "10. Dehumidifier\n",
      "   종합 점수: 0.6005\n",
      "   Dense: 0.589, Sparse: 0.093, ColBERT: 0.796\n",
      "11. DoorLock\n",
      "   종합 점수: 0.5989\n",
      "   Dense: 0.563, Sparse: 0.154, ColBERT: 0.816\n",
      "12. Pump\n",
      "   종합 점수: 0.5944\n",
      "   Dense: 0.575, Sparse: 0.116, ColBERT: 0.782\n",
      "13. Fan\n",
      "   종합 점수: 0.5797\n",
      "   Dense: 0.574, Sparse: 0.074, ColBERT: 0.772\n",
      "14. ContactSensor\n",
      "   종합 점수: 0.5771\n",
      "   Dense: 0.570, Sparse: 0.062, ColBERT: 0.813\n",
      "15. Shade\n",
      "   종합 점수: 0.5747\n",
      "   Dense: 0.562, Sparse: 0.076, ColBERT: 0.817\n"
     ]
    }
   ],
   "source": [
    "# 추천 실행\n",
    "results = hybrid_recommend(\n",
    "    \"날씨가 맑고, 기온이 30도 이상이면 커튼을 닫고 에어컨을 틀고, 미세먼지가 나쁘면 창문을 닫고 공기청정기를 켜줘.\", \n",
    "    top_k=10)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"추천 서비스:\")\n",
    "for idx, item in enumerate(results, 1):\n",
    "    print(f\"{idx}. {item['key']}\")\n",
    "    print(f\"   종합 점수: {item['combined_score']:.4f}\")\n",
    "    print(f\"   Dense: {item['dense_score']:.3f}, Sparse: {item['sparse_score']:.3f}, ColBERT: {item['colbert_score']:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
