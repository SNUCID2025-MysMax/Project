from openai import OpenAI
from dotenv import load_dotenv
import ast
import os
from datetime import datetime
import json
import re
import sys
import random
from conversion import transform_code
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from grammar import grammar
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("apikey")


client = OpenAI(api_key=api_key)

def load_prompt_roles(path, **kwargs):
    with open(path, "r", encoding="utf-8") as f:
        raw = f.read()
    
    messages = []
    parts = re.split(r"###\s*(system|user|assistant)", raw)
    for i in range(1, len(parts), 2):
        role = parts[i].strip()
        content = parts[i+1].strip().format(**kwargs)
        messages.append({"role": role, "content": content})
    
    return messages

    with open(path, "r", encoding="utf-8") as f:
        return f.read().strip()

    with open(file_path, "r", encoding="utf-8") as f:
        return f.read().strip()

# ===  Device í´ë˜ìŠ¤ ë° ê¸°ëŠ¥ ì¶”ì¶œ === #
#def extract_device_skills(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        tree = ast.parse(f.read())

    device_skills = {}

    for node in tree.body:
        if isinstance(node, ast.ClassDef):
            class_name = node.name
            for stmt in node.body:
                if isinstance(stmt, ast.Assign):
                    for target in stmt.targets:
                        if isinstance(target, ast.Name) and target.id == 'skills':
                            skills = []
                            if isinstance(stmt.value, (ast.Set, ast.List)):
                                for elt in stmt.value.elts:
                                    if isinstance(elt, ast.Attribute):
                                        skills.append(elt.attr)
                            if skills:
                                device_skills[class_name] = skills
    return device_skills

def parse_class_docstrings(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read()

    pattern = r'class\s+(\w+)\s*:\s*"""(.*?)"""'
    matches = re.finditer(pattern, text, re.DOTALL)

    class_dict = {}
    for match in matches:
        class_name = match.group(1)
        class_body = match.group(0)
        class_dict[class_name] = class_body.strip()

    return class_dict

def sample_device_classes(class_dict, k=3):
    selected_keys = random.sample(list(class_dict.keys()), k)
    return "\n\n".join(class_dict[k] for k in selected_keys)

import re
from datetime import datetime

def process_refined_commands(client, refined_text, service_doc, max_variants=3):
    data_pairs = []

    # 1. ë²ˆí˜¸ ìˆëŠ” ì¤„ë§Œ ì¶”ì¶œ
    refined_commands = [
        re.sub(r"^\d+\.\s*", "", line).strip()
        for line in refined_text.split("\n")
        if re.match(r"^\d+\.\s*", line.strip())
    ]

    # 2. ëª…ë ¹ì–´ë³„ ìœ ì‚¬ë¬¸ì¥ ë° ì½”ë“œ ìƒì„±
    for idx, command in enumerate(refined_commands, start=1):
        #print(f"\nğŸ“Œ ëª…ë ¹ì–´ {idx}: {command}")
        try:
            # ìœ ì‚¬ ë¬¸ì¥ ìƒì„±
            variants_text = expand_variants(client, command, n=max_variants)
            variants = [
                v.strip(" 1234567890.").strip()
                for v in variants_text.split("\n") if v.strip()
            ]
            all_variants = [command] + variants

            # ì½”ë“œ ìƒì„±
            current_time = datetime.now().strftime("%a, %d %b %Y %H:%M:%S")
            code = generate_python_from_text(client, command, service_doc, current_time)

            # ëª¨ë“  ë¬¸ì¥ì— ë™ì¼í•œ ì½”ë“œ í• ë‹¹
            for i, variant in enumerate(all_variants):
                #print(f"  {i+1}. {variant}")
                data_pairs.append({"text": variant, "code": code})

        except Exception as e:
            print(f"âŒ '{command}' ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    return data_pairs


# ===  GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„± === #
# 1: ë””ë°”ì´ìŠ¤ ìŠ¤í‚¬ ê¸°ë°˜ ëª…ë ¹ ìƒì„±
def generate_commands(client, skills_dict, n=10, example=""):
    devices_str = json.dumps(skills_dict, indent=2, ensure_ascii=False)
    messages = load_prompt_roles("generate_prompt.txt", devices=devices_str, n=n, example=example)

    response = client.chat.completions.create(model="gpt-4", messages=messages, temperature=0.7)
    return response.choices[0].message.content.strip()





# 2: ëª¨í˜¸ì„± ê²€ì‚¬ ë° ìˆ˜ì •
def refine_commands(client, commands_text):
    messages = load_prompt_roles("refine_prompt.txt", commands=commands_text)

    response = client.chat.completions.create(model="gpt-4", messages=messages, temperature=0.7)
    return response.choices[0].message.content.strip()



# 3: ìœ ì‚¬ ëª…ë ¹ì–´ ìƒì„± 
def expand_variants(client, command, n=3):
    messages = load_prompt_roles("variant_prompt.txt", command=command, n=n)

    response = client.chat.completions.create(model="gpt-4", messages=messages, temperature=0.8)
    return response.choices[0].message.content.strip()



# 4: í…ìŠ¤íŠ¸ ëª…ë ¹ì–´ë¥¼ Python ì½”ë“œë¡œ ë³€í™˜ (prompt í…œí”Œë¦¿ ì‚¬ìš©)
def generate_python_from_text(client, user_command, service_doc, current_time):
    prompt = f"""\
# Devices
{service_doc}

# User Command
command: {user_command}

# Current Time
current: {current_time}
"""
    messages = [
        {"role": "system", "content": grammar},
        {"role": "user", "content": prompt}
    ]

    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

# 5: Python code ë¥¼ joi_lang ìœ¼ë¡œ ë³€í™˜
def convert_to_joi_lang(data_pairs):
    joi_pairs = []

    for pair in data_pairs:
        python_code = pair["code"]
        try:
            joi_result = transform_code(python_code)
            if joi_result:
                joi_code = joi_result[0]["code"]
                joi_pairs.append({
                    "text": pair["text"],
                    "code": joi_code
                })
            else:
                print(f"âš ï¸ ë³€í™˜ ì‹¤íŒ¨ (ê²°ê³¼ ì—†ìŒ): {pair['text']}")
        except Exception as e:
            print(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} â€” {pair['text']}")

    return joi_pairs

# 6: ì˜ˆì‹œ ë³€ìˆ˜ ë¡œë“œ
def load_example_variables(path):
    with open(path, "r", encoding="utf-8") as f:
        source = f.read()
    tree = ast.parse(source)

    result = {}
    for node in tree.body:
        if isinstance(node, ast.Assign) and isinstance(node.targets[0], ast.Name):
            var_name = node.targets[0].id
            if isinstance(node.value, ast.Constant) and isinstance(node.value.value, str):
                result[var_name] = node.value.value.strip()
    return result


# === ì‹¤í–‰ === #
if __name__ == "__main__":
    device_docs = parse_class_docstrings("../0.1.3_docstring_v3.txt")
    sampled_device = sample_device_classes(device_docs, k=10)

    examples_by_category = load_example_variables("example.txt")
    base_commands = generate_commands(client, sampled_device, n=20, example=examples_by_category)

    #print("ìƒì„±ëœ ëª…ë ¹ì–´ë“¤\n", base_commands)

    refined_text = refine_commands(client, base_commands)
    #print("âœ… ì •ì œëœ ëª…ë ¹ì–´ë“¤:\n", refined_text)
        
    data_pairs = process_refined_commands(client, refined_text, sampled_device, max_variants=3)
    joi_pairs = convert_to_joi_lang(data_pairs)

    # ğŸ”½ íŒŒì¼ë¡œ ì €ì¥
    output_path = f"generated_output/generated_dataset_{category}.json"
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(joi_pairs, f, ensure_ascii=False, indent=2)
    print(f"\n ì´ {len(joi_pairs)}ê°œì˜ ëª…ë ¹ì–´-ì½”ë“œ ìŒì´ generated_dataset.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."    )
