from openai import OpenAI
from dotenv import load_dotenv
import ast
import os
from datetime import datetime
import json
import re
import sys
import random
from conversion import transform_code
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from grammar import grammar
from conversion import transform_code
import yaml
from yaml.representer import SafeRepresenter

load_dotenv()
apikey = os.getenv("OPENAI_API_KEY")

#print("ğŸ” Loaded API Key:", apikey)
client = OpenAI(api_key=apikey)

def load_prompt_roles(path, **kwargs):
    with open(path, "r", encoding="utf-8") as f:
        raw = f.read()
    
    messages = []
    parts = re.split(r"###\s*(system|user|assistant)", raw)
    for i in range(1, len(parts), 2):
        role = parts[i].strip()
        content = parts[i+1].strip().format(**kwargs)
        messages.append({"role": role, "content": content})
    
    return messages

# ===  Device í´ë˜ìŠ¤ ë° ê¸°ëŠ¥ ì¶”ì¶œ === #
def extract_device_skills(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        tree = ast.parse(f.read())

    device_skills = {}

    for node in tree.body:
        if isinstance(node, ast.ClassDef):
            class_name = node.name
            for stmt in node.body:
                if isinstance(stmt, ast.Assign):
                    for target in stmt.targets:
                        if isinstance(target, ast.Name) and target.id == 'skills':
                            skills = []
                            if isinstance(stmt.value, (ast.Set, ast.List)):
                                for elt in stmt.value.elts:
                                    if isinstance(elt, ast.Attribute):
                                        skills.append(elt.attr)
                            if skills:
                                device_skills[class_name] = skills
    return device_skills

def parse_class_docstrings(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read()

    pattern = r'class\s+(\w+)\s*:\s*"""(.*?)"""'
    matches = re.finditer(pattern, text, re.DOTALL)

    class_dict = {}
    for match in matches:
        class_name = match.group(1)
        class_body = match.group(0)
        class_dict[class_name] = class_body.strip()

    return class_dict

def sample_device_classes(class_dict, k=3):
    selected_keys = random.sample(list(class_dict.keys()), k)
    return "\n\n".join(class_dict[k] for k in selected_keys)

import re
from datetime import datetime

def process_refined_commands(client, base_commands, service_doc, max_variants):
    data_pairs = []
    if isinstance(base_commands, str):
        base_commands = [
            line.strip(" 1234567890.-").strip()
            for line in base_commands.split("\n")
            if line.strip()
        ]
    for command in base_commands:
        #print(command)
        try:
            # ìœ ì‚¬ ë¬¸ì¥ ìƒì„±
            variants_text = expand_variants(client, command, n=max_variants)
            variants = [
                v.strip(" 1234567890.").strip()
                for v in variants_text.split("\n") if v.strip()
            ]
            all_variants = [command] + variants
            #print(all_variants)

            # ì½”ë“œ ìƒì„±
            current_time = datetime.now().strftime("%a, %d %b %Y %H:%M:%S")
            code_obj = generate_python_from_text(client, command, service_doc, current_time)
            code_obj = transform_code(code_obj)[0]

            for variant in all_variants:
                data_pairs.append({"text": variant, "code": code_obj})


        except Exception as e:
            print(f"âŒ '{command}' ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    return data_pairs


# ===  GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„± === #
# 1: ë””ë°”ì´ìŠ¤ ìŠ¤í‚¬ ê¸°ë°˜ ëª…ë ¹ ìƒì„±


def generate_commands(client, skills_dict, n, examples="", category_context=""):
    devices_str = json.dumps(skills_dict, indent=2, ensure_ascii=False)
    if isinstance(examples, list):
        examples = "\n".join(f"{i+1}. {ex}" for i, ex in enumerate(examples))

    messages = load_prompt_roles(
        "generate_prompt_english.txt", 
        devices=devices_str, 
        n=n, 
        examples=examples, 
        context=category_context
    )

    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        temperature=0.7,
    )
    usage = response.usage
    # print(response.choices[0].message.content.strip())
    # print("Input tokens:", usage.prompt_tokens)
    # print("Output tokens:", usage.completion_tokens)
    return response.choices[0].message.content.strip()





# 2: ëª¨í˜¸ì„± ê²€ì‚¬ ë° ìˆ˜ì •
def refine_commands(client, commands_text):
    messages = load_prompt_roles("refine_prompt.txt", commands=commands_text)

    response = client.chat.completions.create(model="gpt-4", messages=messages, temperature=0.7)
    return response.choices[0].message.content.strip()



# 3: ìœ ì‚¬ ëª…ë ¹ì–´ ìƒì„± 
def expand_variants(client, example, n):
    messages = load_prompt_roles("variant_prompt_english.txt", command=example, n=n)
    
    response = client.chat.completions.create(model="gpt-4", messages=messages, temperature=0.8)
    # print("  Prompt tokens   :", response.usage.prompt_tokens)
    # print("  Completion tokens:", response.usage.completion_tokens)
    return response.choices[0].message.content.strip()



# 4: í…ìŠ¤íŠ¸ ëª…ë ¹ì–´ë¥¼ Python ì½”ë“œë¡œ ë³€í™˜ (prompt í…œí”Œë¦¿ ì‚¬ìš©)
def generate_python_from_text(client, user_command, service_doc, current_time):
    prompt = f"""\
# Devices
{service_doc}

# User Command
command: {user_command}

# Current Time
current: {current_time}

# Output Format (SoPLang JSON)
Please generate a full SoPLang JSON block with:
- "cron"
- "period"
- "script"

"""
    messages = [
        {"role": "system", "content": grammar},
        {"role": "user", "content": prompt}
    ]

    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        temperature=0.7
    )
    usage = response.usage
    print(response.choices[0].message.content.strip())
    print("Input tokens:", usage.prompt_tokens)
    print("Output tokens:", usage.completion_tokens)
    content = response.choices[0].message.content.strip()
    
    return content

def convert_data_pairs_to_joi_pairs(data_pairs):
    joi_pairs = []
    for pair in data_pairs:
        print(pair)
        print(pair.get("cron"))
        text = pair["text"]
        cron = pair.get("cron", "")
        period = pair.get("period", -1)
        script_code = pair["script"]

        joi_item = transform_code(script_code)[0]
        joi_pairs.append({
            "text": text,
            "cron": cron,
            "period": period,
            "code": joi_item["code"]
        })

    return joi_pairs



def load_command_examples(file_num, start=0, end=None):
    folder_path = r"C:\Users\ê¹€ì§€í›„\Downloads\testt\Project\Testset\TestsetWithDevices_translated"
    yaml_file = os.path.join(folder_path, f"category_{file_num}.yaml")
    
    examples = []
    if os.path.exists(yaml_file):
        with open(yaml_file, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
            examples.extend(data)

    selected = examples[start:end] if end else examples
    return selected


# 5: Python code ë¥¼ joi_lang ìœ¼ë¡œ ë³€í™˜
def convert_to_joi_lang(data_pairs):
    joi_pairs = []

    for pair in data_pairs:
        python_code = pair["code"]
        try:
            joi_result = transform_code(python_code)
            if joi_result:
                joi_code = joi_result[0]["code"]
                joi_pairs.append({
                    "text": pair["text"],
                    "code": joi_code
                })
            else:
                print(f"âš ï¸ ë³€í™˜ ì‹¤íŒ¨ (ê²°ê³¼ ì—†ìŒ): {pair['text']}")
        except Exception as e:
            print(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} â€” {pair['text']}")

    return joi_pairs

# 6: ì˜ˆì‹œ ë³€ìˆ˜ ë¡œë“œ
def load_example_variables(path):
    with open(path, "r", encoding="utf-8") as f:
        source = f.read()
    tree = ast.parse(source)

    result = {}
    for node in tree.body:
        if isinstance(node, ast.Assign) and isinstance(node.targets[0], ast.Name):
            var_name = node.targets[0].id
            if isinstance(node.value, ast.Constant) and isinstance(node.value.value, str):
                result[var_name] = node.value.value.strip()
    return result

def extract_device_definitions(devices, device_docs):
    selected_definitions = []

    for dev in devices:
        if dev in device_docs:
            selected_definitions.append(device_docs[dev])
        else:
            print(f"[WARN] '{dev}' not found in device_docs")

    return "\n\n".join(selected_definitions)

def generate_variants(examples, device_docs):
    prompt_path = "device_variants.txt"  
    updated_examples = []

    for example in examples:
        devices = example["devices"]
        code_entry = example["code"][0]
        original_command = example["command_translated"]
        original_code = code_entry["code"]

        selected_devices = extract_device_definitions(devices, device_docs)

        messages = load_prompt_roles(
            path=prompt_path,
            device_classes=selected_devices,
            original_command = original_command,
            original_code=original_code
        )

        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7
        )
        content = response.choices[0].message.content.strip()
        # print("  Prompt tokens   :", response.usage.prompt_tokens)
        # print("  Completion tokens:", response.usage.completion_tokens)
        
        variants = re.split(r"\n---+\s*", content)
        
        for variant in variants:
            if not variant.strip():
                continue  # ë¹ˆ ë¸”ë¡ ë¬´ì‹œ

            english_match = re.search(r"(?i)ENGLISH:\s*(.*?)\s*CODE:", variant, re.DOTALL)
            code_match = re.search(r"(?i)CODE:\s*(.*)", variant, re.DOTALL)

            if not english_match or not code_match:
                print("[WARN] Skipped malformed variant:\n", variant)
                continue

            new_command = english_match.group(1).strip()
            new_code = code_match.group(1).strip()

            updated_example = {
                "command": new_command,
                "code": [{
                    **code_entry,
                    "code": new_code
                }]
            }

            updated_examples.append(updated_example)

    return updated_examples
def augment_commands_only(generated_examples, client, n=3):
    augmented = []

    for example in generated_examples:
        base_command = example["command"]
        code_copy = example["code"]

        # GPTë¡œ command paraphrase í™•ì¥
        try:
            variants_text = expand_variants(client, base_command, n=n)
            variants = [
                v.strip(" 1234567890.-").strip()
                for v in variants_text.split("\n")
                if v.strip()
            ]
            all_commands = [base_command] + variants  # ì›ë³¸ë„ í¬í•¨

            for cmd in all_commands:
                augmented.append({
                    "command": cmd,
                    "code": code_copy
                })

        except Exception as e:
            print(f"[âŒ] Command augmentation failed: {base_command}\n{e}")

    return augmented

def apply_parameter_tuning_and_save(augmented_examples, client, num, prompt_path="parameter_tuning.txt"):
    os.makedirs("trainset", exist_ok=True)
    total_variants = []
    for example in augmented_examples:
        script_code = example["code"][0]["code"]
        messages = load_prompt_roles(
            path=prompt_path,
            original_code=script_code,
        )

        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7
        )
        print("  Prompt tokens   :", response.usage.prompt_tokens)
        print("  Completion tokens:", response.usage.completion_tokens)

        content = response.choices[0].message.content.strip()
        print(content)
        # --- êµ¬ë¶„ì ê¸°ì¤€ìœ¼ë¡œ ì—¬ëŸ¬ variant ì¶”ì¶œ
        variants = []
        for block in re.split(r"\n---+\s*", content):
            if not block.strip():
                continue

            match_eng = re.search(r"(?i)ENGLISH:\s*(.*?)\s*CODE:", block, re.DOTALL)
            match_code = re.search(r"(?i)CODE:\s*(.*)", block, re.DOTALL)
            if not match_eng or not match_code:
                print(f"[WARN] Skipping unparsable block:\n{block}")
                continue
            script_body = match_code.group(1).strip()

            # cronê³¼ period ê°’ íŒŒì‹± ì‹œë„
            cron_match = re.search(r'"?cron"?\s*:\s*"([^"]*)"', script_body)
            period_match = re.search(r'"?period"?\s*:\s*(-?\d+)', script_body)

            cron = cron_match.group(1).strip() if cron_match else example["code"][0]["cron"]
            period = int(period_match.group(1)) if period_match else example["code"][0]["period"]

            variants.append({
                "command": match_eng.group(1).strip(),
                "code": [{
                    "name": example["code"][0]["name"],
                    "cron": cron,
                    "period": period,
                    "code": script_body
                }]
            })
            
        output_examples = variants if variants else [example]
        total_variants.extend(output_examples)
        
        output_path = f"trainset/generated_data_{num}.json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(variants, f, indent=2, ensure_ascii=False)

    return print(f"\n ì´ {len(total_variants)}ê°œì˜ ëª…ë ¹ì–´-ì½”ë“œ ìŒì´ generated_dataset_1.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
def tune_examples_pythonically(augmented_examples):
    cron_options = ["0 10 * * *", "0 18 * * *"]
    period_options = [15000, 20000]
    param_range = range(10, 41, 5)  # ì˜ˆ: 10~40 ì‚¬ì´ ìˆ«ì

    tuned = []

    for ex in augmented_examples:
        base = ex.copy()
        code_block = base["code"][0]

        # 1. cron íŠœë‹ (ì¡´ì¬í•˜ë©´)
        if code_block["cron"].strip():
            code_block["cron"] = random.choice(cron_options)

        # 2. period íŠœë‹ (ë‹¨, -1 ë˜ëŠ” 100ì´ë©´ ìœ ì§€)
        if code_block["period"] not in [-1, 100]:
            code_block["period"] = random.choice(period_options)

        # 3. parameter (ìˆ«ì) ì¹˜í™˜
        code_str = code_block["code"]

        # ì •ê·œì‹ìœ¼ë¡œ '== ìˆ«ì' íŒ¨í„´ ì°¾ì•„ì„œ ëœë¤ ê°’ìœ¼ë¡œ ì¹˜í™˜
        def replace_param(match):
            old_val = match.group(1)
            new_val = str(random.choice(param_range))
            return f"== {new_val}"

        new_code = re.sub(r"==\s*(\d+)", replace_param, code_str)
        code_block["code"] = new_code

        tuned.append(base)

    return tuned

def save_augmented_examples_to_trainset(augmented_examples, file_num=1):
    os.makedirs("trainset", exist_ok=True)
    output_path = f"trainset/generated_data_{file_num}.json"

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(augmented_examples, f, indent=2, ensure_ascii=False)
    print(f"âœ… {len(augmented_examples)}ê°œì˜ ì˜ˆì œê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return 

# === ì‹¤í–‰ === #
if __name__ == "__main__":
    device_docs = parse_class_docstrings("../0.1.3_docstring_v3.txt")
    file_num = 6
    for i in range(3,4):
        file_num = i
        examples = load_command_examples(file_num, start=5, end=10)
        generated_examples = generate_variants(examples, device_docs)
        augmented_examples = augment_commands_only(generated_examples, client, n=3)
        save_augmented_examples_to_trainset(augmented_examples, file_num)
    #apply_parameter_tuning_and_save(augmented_examples, client, file_num)

    