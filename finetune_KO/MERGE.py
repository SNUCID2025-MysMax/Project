from peft import PeftModel

# base model ë¶ˆëŸ¬ì˜¤ê¸°
from transformers import AutoModelForCausalLM

base_model = AutoModelForCausalLM.from_pretrained(
    "LGAI-EXAONE/EXAONE-Deep-7.8B",
    trust_remote_code=True,
    torch_dtype="auto",
    device_map=None
)

# LoRA ì ìš© ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = PeftModel.from_pretrained(base_model, "lora_exaone_adapter")

# ğŸ” Merge: LoRA ê°€ì¤‘ì¹˜ë¥¼ base modelì— í†µí•©
model = model.merge_and_unload()

model.save_pretrained("merged_exaone")